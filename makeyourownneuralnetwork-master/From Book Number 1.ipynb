{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class neuralNetwork:\n",
    "    \n",
    "    def __init__(self,inputnodes,hiddennodes, outputnodes, learningrate):\n",
    "        self.inodes=inputnodes\n",
    "        self.hnodes=hiddennodes\n",
    "        self.onodes=outputnodes\n",
    "        self.lr=learningrate\n",
    "        self.whi=numpy.random.normal(0.0,pow(self.hnodes,-.5), (self.hnodes, self.inodes))\n",
    "        self.who=numpy.random.normal(0.0,pow(self.onodes,-.5), (self.onodes, self.hnodes))\n",
    "        self.activation_function= lambda x: scipy.special.expit(x)\n",
    "        pass\n",
    " \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        #converts input list to 2d array\n",
    "        inputs=numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        targets =numpy.array(targets_list,ndmin=2).T\n",
    "        \n",
    "        #calc signals input into hidden layer\n",
    "        hidden_inputs=numpy.dot(self.whi, inputs)\n",
    "        \n",
    "        # activate hidden layer\n",
    "        hidden_outputs=self.activation_function(hidden_inputs)\n",
    "        \n",
    "        \n",
    "        #calc final outputs\n",
    "        final_inputs =numpy.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        # activate final output\n",
    "        final_outputs=self.activation_function(final_inputs)\n",
    "        \n",
    "        #error\n",
    "        output_errors=targets -final_outputs\n",
    "        \n",
    "        #hidden errors\n",
    "        hidden_errors= numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "        #calc the who\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs* (1.0- final_outputs)),numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        self.whi += self.lr * numpy.dot((hidden_errors * hidden_outputs* (1.0- hidden_outputs)),numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def query(self, input_lists):\n",
    "        #converts input list to 2d array\n",
    "        inputs=numpy.array(input_lists, ndmin=2).T\n",
    "        \n",
    "        #calc signals input into hidden layer\n",
    "        hidden_inputs=numpy.dot(self.whi, inputs)\n",
    "        \n",
    "        # activate hidden layer\n",
    "        hidden_outputs=self.activation_function(hidden_inputs)\n",
    "        \n",
    "        \n",
    "        #calc final outputs\n",
    "        final_inputs =numpy.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        # activate final output\n",
    "        final_outputs=self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows is :  60000\n",
      "Epoch #: 1\n",
      "Now on #: 0\n",
      "Epoch #: 1\n",
      "Now on #: 6000\n",
      "Epoch #: 1\n",
      "Now on #: 12000\n",
      "Epoch #: 1\n",
      "Now on #: 18000\n",
      "Epoch #: 1\n",
      "Now on #: 24000\n",
      "Epoch #: 1\n",
      "Now on #: 30000\n",
      "Epoch #: 1\n",
      "Now on #: 36000\n",
      "Epoch #: 1\n",
      "Now on #: 42000\n",
      "Epoch #: 1\n",
      "Now on #: 48000\n",
      "Epoch #: 1\n",
      "Now on #: 54000\n"
     ]
    }
   ],
   "source": [
    "training_data_file=open(\"mnist_dataset/mnist_train.csv\",\"r\")\n",
    "training_data_list=training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "input_nodes=784\n",
    "hidden_nodes=10\n",
    "output_nodes=10\n",
    "learning_rate=.22\n",
    "total_images_to_process=len(training_data_list)\n",
    "print(\"The number of rows is : \",total_images_to_process)\n",
    "\n",
    "n=neuralNetwork(input_nodes,hidden_nodes, output_nodes, learning_rate)\n",
    "epochs=1\n",
    "counter=0\n",
    "for e in range(epochs):\n",
    "    for record in training_data_list:\n",
    "        \n",
    "        all_values=record.split(',')\n",
    "        inputs =(numpy.asfarray(all_values[1:]) /255 * .99 ) + .01\n",
    "        targets=numpy.zeros(output_nodes) + .01\n",
    "        targets[int(all_values[0])]=.99\n",
    "        n.train(inputs, targets)\n",
    "        if (counter % (total_images_to_process/10)) ==0:\n",
    "            print(\"Epoch #:\", e + 1)\n",
    "            print('Now on #:',counter)\n",
    "        counter =counter + 1\n",
    "        if (counter ==total_images_to_process):\n",
    "            counter=0;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_nodes=3\n",
    "hidden_nodes =3\n",
    "output_nodes=3\n",
    "learning_rate=0.3\n",
    "\n",
    "n=neuralNetwork(input_nodes,hidden_nodes, output_nodes, learning_rate)\n",
    "n.query([1.0,0.5,-1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data_file =open(\"mnist_dataset/mnist_test.csv\",\"r\")\n",
    "test_data_list=test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_values=test_data_list[0].split(',')\n",
    "print(all_values[0]),\n",
    "image_array=numpy.asfarray(all_values[1:]).reshape(28,28)\n",
    "matplotlib.pyplot.imshow(image_array)\n",
    "matplotlib.pyplot.imshow(image_array, cmap=\"Greys\")\n",
    "matplotlib.pyplot.imshow(image_array, cmap=\"Greys\",interpolation='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n.query(((numpy.asfarray(all_values[1:])) / 255.0 * .99)+ .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size 60000\n",
      "hidden layers 10\n",
      "learning rate 0.22\n",
      "epochs 2\n",
      "permformance = 0.8666\n"
     ]
    }
   ],
   "source": [
    "scorecard=[]\n",
    "for record in test_data_list:\n",
    "    all_values=record.split(',')\n",
    "    correct_label=int(all_values[0])\n",
    "    #print(correct_label,\"correct label\")\n",
    "    inputs =(numpy.asfarray(all_values[1:])/255 *.99) + .01\n",
    "    outputs=n.query(inputs)\n",
    "    label=numpy.argmax(outputs)\n",
    "    #print(label,\"networks answer\")\n",
    "    if (label==correct_label):\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        scorecard.append(0)\n",
    "scorecard_array=numpy.array(scorecard)\n",
    "print('training set size', len(training_data_list))\n",
    "print('hidden layers',hidden_nodes)\n",
    "print('learning rate', learning_rate)\n",
    "print('epochs',epochs)\n",
    "print(\"permformance =\",scorecard_array.sum()/scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
